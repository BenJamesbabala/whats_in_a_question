## Image Descriptions

We analyze whether the visual questions contain enough information to provide an accurate description of the image using the Seq2Seq model. See [NeuralTalk2](https://github.com/karpathy/neuraltalk2) and [Seq2Seq models](https://www.tensorflow.org/tutorials/seq2seq) for image caption generation. 



Replace the Seq2Seq datafiles in place of the placeholders present in the repository. Use these in place of the French and English dataset in the [Seq2Seq models](https://www.tensorflow.org/tutorials/seq2seq).

Datafiles:
 
1. [Training_captions](https://cmu.box.com/s/0g4qwrhq56uppjptqktld62paihabpzg)
2. [Training_questions](https://cmu.box.com/s/uc60x9andchvhhs1vi1qg2t9igytb5bm)